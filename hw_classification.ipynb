{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementing Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement Logistic Regression with l2 regularization using gradient descent algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression loss:\n",
    "$$ L(w) = \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + e^{-\\langle w, x_i \\rangle y_i}) + \\frac{1}{2C} \\lVert w \\rVert^2  \\to \\min_w$$\n",
    "$$\\langle w, x_i \\rangle = \\sum_{j=1}^n w_{j}x_{ij} + w_{0},$$ $$ y_{i} \\in \\{-1, 1\\}$$ where $n$ is the number of features and $N$ is the number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent step:\n",
    "$$w^{(t+1)} := w^{(t)} + \\dfrac{\\eta}{N}\\sum_{i=1}^N y_ix_i \\Big(1 - \\dfrac{1}{1 + exp(-\\langle w^{(t)}, x_i \\rangle y_i)}\\Big) - \\eta \\frac{1}{C} w,$$\n",
    "where $\\eta$ is the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) into \"even\" and \"odd\" categories. \"Even\" and \"Odd\" classes  should correspond to {-1, 1} labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping criteria: either the number of iterations exceeds *max_iter* or $||w^{(t+1)} - w^{(t)}||_2 < tol$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, eta=0.001, max_iter=1000, C=1.0, tol=1e-5, random_state=42, zero_init=False):\n",
    "        \"\"\"Logistic Regression classifier.\n",
    "        \n",
    "        Args:\n",
    "            eta: float, default=0.001\n",
    "                Learning rate.\n",
    "            max_iter: int, default=1000\n",
    "                Maximum number of iterations taken for the solvers to converge.\n",
    "            C: float, default=1.0\n",
    "                Inverse of regularization strength; must be a positive float.\n",
    "                Smaller values specify stronger regularization.\n",
    "            tol: float, default=1e-5\n",
    "                Tolerance for stopping criteria.\n",
    "            random_state: int, default=42\n",
    "                Random state.\n",
    "            zero_init: bool, default=False\n",
    "                Zero weight initialization.\n",
    "        \"\"\"\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.C = C\n",
    "        self.tol = tol\n",
    "        self.random_state = np.random.RandomState(seed=random_state)\n",
    "        self.zero_init = zero_init\n",
    "         \n",
    "    def get_sigmoid(self, X, weights):\n",
    "        \"\"\"Compute the sigmoid value.\"\"\"\n",
    "        # <your code>\n",
    "       \n",
    "        return  1. / (1 + np.exp(-weights*X))\n",
    "    \n",
    "    def get_loss(self, x, weights, y):\n",
    "        \"\"\"Calculate the loss.\"\"\"\n",
    "        # <your code>\n",
    "        \n",
    "        return np.log(1 + np.exp(-y*weights.T*x))\n",
    "     \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X]) # a constant feature is included to handle intercept\n",
    "        num_features = X_ext.shape[1]\n",
    "        if self.zero_init:\n",
    "            self.weights_ = np.zeros(num_features) \n",
    "        else:\n",
    "            weight_threshold = 1.0 / (2 * num_features)\n",
    "            self.weights_ = self.random_state.uniform(low=-weight_threshold,\n",
    "                                                      high=weight_threshold, size=num_features) # random weight initialization\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            delta = self.weights_/self.C- np.dot(X_ext.T,(self.get_sigmoid(X_ext, self.weights_)-y[:, np.newaxis]))/len(y)\n",
    "            self.weights_ -= self.eta * delta\n",
    "                    \n",
    "            \n",
    "            \n",
    "            if np.linalg.norm(delta, 2) < self.tol:\n",
    "                break\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        X_ext = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "        if hasattr(self, 'weights_'):\n",
    "            return self.get_sigmoid(X_ext, self.weights_)\n",
    "        else: \n",
    "            raise NotFittedError(\"CustomLogisticRegression instance is not fitted yet\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        if x is None:\n",
    "            x = self.x\n",
    "        y_pred_proba = self._f(x, self.weights_, self.–°)\n",
    "        y_pred = np.array([0 if y_pred_proba[i] < 0.5 else 1 for i in range(len(y_pred_proba))])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "#y_train = \"<your code>\"\n",
    "#y_test = \"<your code>\"\n",
    "y_train = (y_train % 2) * 2 - 1\n",
    "y_test = (y_test % 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.unique(y_train) == [-1, 1]).all()\n",
    "assert (np.unique(y_test) == [-1, 1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    disp = metrics.plot_confusion_matrix(clf, X_test, y_test, normalize='true')\n",
    "    disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(y_pred=clf.predict(X_train), y_true=y_train), \\\n",
    "           metrics.accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = CustomLogisticRegression(max_iter=1, zero_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,3) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [485]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.58662\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.40131\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2251\u001b[0m, in \u001b[0;36mallclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[0;32m   2181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mallclose\u001b[39m(a, b, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-5\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.e-8\u001b[39m, equal_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   2182\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2183\u001b[0m \u001b[38;5;124;03m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[0;32m   2184\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2249\u001b[0m \n\u001b[0;32m   2250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2251\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m(\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(res)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2361\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2359\u001b[0m yfin \u001b[38;5;241m=\u001b[39m isfinite(y)\n\u001b[0;32m   2360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xfin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(yfin):\n\u001b[1;32m-> 2361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwithin_tol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     finite \u001b[38;5;241m=\u001b[39m xfin \u001b[38;5;241m&\u001b[39m yfin\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\numeric.py:2342\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[1;34m(x, y, atol, rtol)\u001b[0m\n\u001b[0;32m   2340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[0;32m   2341\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m-> 2342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m less_equal(\u001b[38;5;28mabs\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43my\u001b[49m), atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m(y))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,3) (2,) "
     ]
    }
   ],
   "source": [
    "assert np.allclose(lr_clf.get_sigmoid(np.array([[0.5, 0, 1.0], [0.3, 1.3, 1.0]]), np.array([0.5, -0.5, 0.1])),\n",
    "                   np.array([0.58662, 0.40131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (65,) doesn't match the broadcast shape (65,65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [486]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlr_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [479]\u001b[0m, in \u001b[0;36mCustomLogisticRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m     59\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC\u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_ext\u001b[38;5;241m.\u001b[39mT,(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sigmoid(X_ext, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_)\u001b[38;5;241m-\u001b[39my[:, np\u001b[38;5;241m.\u001b[39mnewaxis]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta \u001b[38;5;241m*\u001b[39m delta\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(delta, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (65,) doesn't match the broadcast shape (65,65)"
     ]
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [487]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(lr_clf\u001b[38;5;241m.\u001b[39mweights_, np\u001b[38;5;241m.\u001b[39marray([ \u001b[38;5;241m3.1000e-06\u001b[39m,  \u001b[38;5;241m0.0000e+00\u001b[39m,  \u001b[38;5;241m4.1800e-05\u001b[39m,  \u001b[38;5;241m5.4770e-04\u001b[39m,  \u001b[38;5;241m2.2130e-04\u001b[39m,\n\u001b[0;32m      2\u001b[0m         \u001b[38;5;241m4.8750e-04\u001b[39m,  \u001b[38;5;241m1.3577e-03\u001b[39m,  \u001b[38;5;241m5.9780e-04\u001b[39m,  \u001b[38;5;241m5.6400e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.0000e-07\u001b[39m,\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;241m1.6910e-04\u001b[39m,  \u001b[38;5;241m2.5190e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.3700e-04\u001b[39m,  \u001b[38;5;241m3.6190e-04\u001b[39m,  \u001b[38;5;241m1.0049e-03\u001b[39m,\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;241m4.2280e-04\u001b[39m,  \u001b[38;5;241m2.5700e-05\u001b[39m,  \u001b[38;5;241m3.0000e-07\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.1500e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.2440e-04\u001b[39m,\n\u001b[0;32m      5\u001b[0m        \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.6200e-04\u001b[39m,  \u001b[38;5;241m8.7540e-04\u001b[39m,  \u001b[38;5;241m4.1540e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8.4200e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.2000e-06\u001b[39m,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;241m0.0000e+00\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.2160e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.7130e-04\u001b[39m,  \u001b[38;5;241m9.8570e-04\u001b[39m,  \u001b[38;5;241m1.3507e-03\u001b[39m,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;241m5.0210e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.7050e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0000e-06\u001b[39m,  \u001b[38;5;241m0.0000e+00\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6.7810e-04\u001b[39m,\n\u001b[0;32m      8\u001b[0m        \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0515e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.4500e-05\u001b[39m,  \u001b[38;5;241m3.7160e-04\u001b[39m,  \u001b[38;5;241m4.2100e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8.1800e-05\u001b[39m,\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;241m0.0000e+00\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.2000e-06\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.3410e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.0393e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8.4310e-04\u001b[39m,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;241m1.0400e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.2390e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.7880e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.3200e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.5000e-06\u001b[39m,\n\u001b[0;32m     11\u001b[0m        \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9.4300e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.1127e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.0900e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.1850e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.6050e-04\u001b[39m,\n\u001b[0;32m     12\u001b[0m        \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.9560e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.7700e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.0000e-07\u001b[39m,  \u001b[38;5;241m2.6800e-05\u001b[39m,  \u001b[38;5;241m6.3920e-04\u001b[39m,\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;241m1.8090e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.3660e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.3930e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.7060e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.8200e-05\u001b[39m]), atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(lr_clf.weights_, np.array([ 3.1000e-06,  0.0000e+00,  4.1800e-05,  5.4770e-04,  2.2130e-04,\n",
    "        4.8750e-04,  1.3577e-03,  5.9780e-04,  5.6400e-05, -7.0000e-07,\n",
    "        1.6910e-04,  2.5190e-04, -4.3700e-04,  3.6190e-04,  1.0049e-03,\n",
    "        4.2280e-04,  2.5700e-05,  3.0000e-07, -1.1500e-05, -7.2440e-04,\n",
    "       -2.6200e-04,  8.7540e-04,  4.1540e-04, -8.4200e-05, -5.2000e-06,\n",
    "        0.0000e+00, -2.2160e-04, -5.7130e-04,  9.8570e-04,  1.3507e-03,\n",
    "        5.0210e-04, -1.7050e-04, -1.0000e-06,  0.0000e+00, -6.7810e-04,\n",
    "       -1.0515e-03, -4.4500e-05,  3.7160e-04,  4.2100e-04, -8.1800e-05,\n",
    "        0.0000e+00, -5.2000e-06, -5.3410e-04, -2.0393e-03, -8.4310e-04,\n",
    "        1.0400e-04, -1.2390e-04, -1.7880e-04, -1.3200e-05, -4.5000e-06,\n",
    "       -9.4300e-05, -1.1127e-03, -5.0900e-04, -2.1850e-04, -5.6050e-04,\n",
    "       -3.9560e-04, -1.7700e-05, -3.0000e-07,  2.6800e-05,  6.3920e-04,\n",
    "        1.8090e-04, -7.3660e-04, -5.3930e-04, -3.7060e-04, -2.8200e-05]), atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (65,) doesn't match the broadcast shape (65,65)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [489]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_acc, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mfit_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [483]\u001b[0m, in \u001b[0;36mfit_evaluate\u001b[1;34m(clf, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_evaluate\u001b[39m(clf, X_train, y_train, X_test, y_test):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     disp \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mplot_confusion_matrix(clf, X_test, y_test, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     disp\u001b[38;5;241m.\u001b[39mfigure_\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [479]\u001b[0m, in \u001b[0;36mCustomLogisticRegression.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m     59\u001b[0m     delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC\u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_ext\u001b[38;5;241m.\u001b[39mT,(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sigmoid(X_ext, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_)\u001b[38;5;241m-\u001b[39my[:, np\u001b[38;5;241m.\u001b[39mnewaxis]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta \u001b[38;5;241m*\u001b[39m delta\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(delta, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (65,) doesn't match the broadcast shape (65,65)"
     ]
    }
   ],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [227]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[43mtrain_acc\u001b[49m, test_acc) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.9\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_acc' is not defined"
     ]
    }
   ],
   "source": [
    "assert min(train_acc, test_acc) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Visualize the loss history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different learning rates and compare the results. How does the learning rate influence the convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different regularization parameter values and compare the model quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare zero initialization and random initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you need to implement weighted K-Neighbors Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that training a KNN classifier is simply memorizing a training sample. \n",
    "\n",
    "The process of applying a classifier for one object is to find the distances from it to all objects in the training data, then select the k nearest objects (neighbors) and return the most common class among these objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also give the nearest neighbors weights in accordance with the distance of the object to them. In the simplest case (as in your assignment), you can set the weights inversely proportional to that distance. \n",
    "\n",
    "$$w_{i} = \\frac{1}{d_{i} + eps},$$\n",
    "\n",
    "where $d_{i}$ is the distance between object and i-th nearest neighbor and $eps$ is the small value to prevent division by zero.\n",
    "\n",
    "In case of 'uniform' weights, all k nearest neighbors are equivalent (have equal weight, for example $w_{i} = 1, \\forall i \\in(1,k)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the probability of classes, it is necessary to normalize the weights of each class, dividing them by the sum:\n",
    "\n",
    "$$p_{i} = \\frac{w_{i}}{\\sum_{j=1}^{c}w_{j}},$$\n",
    "\n",
    "where $p_i$ is probability of i-th class and $c$ is the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2 points)** Implement the algorithm and use it to classify the digits. By implementing this algorithm, you will be able to classify numbers not only into \"even\" or \"odd\", but into their real representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomKNeighborsClassifier:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, weights='uniform', eps=1e-9):\n",
    "        \"\"\"K-Nearest Neighbors classifier.\n",
    "        \n",
    "        Args:\n",
    "            n_neighbors: int, default=5\n",
    "                Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
    "            weights : {'uniform', 'distance'} or callable, default='uniform'\n",
    "                Weight function used in prediction.  Possible values:\n",
    "                - 'uniform' : uniform weights.  All points in each neighborhood\n",
    "                  are weighted equally.\n",
    "                - 'distance' : weight points by the inverse of their distance.\n",
    "                  in this case, closer neighbors of a query point will have a\n",
    "                  greater influence than neighbors which are further away.\n",
    "            eps : float, default=1e-5\n",
    "                Epsilon to prevent division by 0 \n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.eps = eps\n",
    "        \n",
    "    \n",
    "    def get_pairwise_distances(self, X, Y):\n",
    "        \"\"\"\n",
    "        Returnes matrix of the pairwise distances between the rows from both X and Y.\n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            Y: numpy array of shape (k_samples, n_features)\n",
    "        Returns:\n",
    "            P: numpy array of shape (n_samples, k_samples)\n",
    "                Matrix in which (i, j) value is the distance \n",
    "                between i'th row from the X and j'th row from the Y.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        Y = X if Y is None else Y\n",
    "        xx = (X ** 2).sum(axis = 1)[:, None]\n",
    "        yy = (Y ** 2).sum(axis = 1)[:, None]\n",
    "        d = xx + yy.T - 2 * (X @ Y.T) \n",
    "        return d\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_class_weights(self, y, weights):\n",
    "        \"\"\"\n",
    "        Returns a vector with sum of weights for each class \n",
    "        Args:\n",
    "            y: numpy array of shape (n_samles,)\n",
    "            weights: numpy array of shape (n_samples,)\n",
    "                The weights of the corresponding points of y.\n",
    "        Returns:\n",
    "            p: numpy array of shape (n_classes)\n",
    "                Array where the value at the i-th position \n",
    "                corresponds to the weight of the i-th class.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        ùë§ùëñ=self.get_pairwise_distances+self.ùëíùëùùë†\n",
    "            \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Target vector.        \n",
    "        \"\"\"\n",
    "        self.points = X\n",
    "        self.y = y\n",
    "        self.classes_ = np.unique(y)\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict positive class probabilities.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples, n_classes)\n",
    "                Vector containing positive class probabilities.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'points'):\n",
    "            P = self.get_pairwise_distances(X, self.points)\n",
    "            \n",
    "            weights_of_points = np.ones(P.shape)\n",
    "            if self.weights == 'distance':\n",
    "                weights_of_points = 'your code'\n",
    "                \n",
    "            # <your code>\n",
    "            pass\n",
    "        \n",
    "        else: \n",
    "            raise NotFittedError(\"CustomKNeighborsClassifier instance is not fitted yet\")\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict classes.\n",
    "        \n",
    "        Args:\n",
    "            X: numpy array of shape (n_samples, n_features)\n",
    "        Returns:\n",
    "            y: numpy array of shape (n_samples,)\n",
    "                Vector containing predicted class labels.\n",
    "        \"\"\"\n",
    "        # <your code>\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomKNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [502]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(model\u001b[38;5;241m.\u001b[39mget_pairwise_distances(np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m  , \u001b[38;5;241m1\u001b[39m]  , [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]]), \n\u001b[0;32m      2\u001b[0m                                                 np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]])),\n\u001b[0;32m      3\u001b[0m                    np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.70710678\u001b[39m, \u001b[38;5;241m1.41421356\u001b[39m],\n\u001b[0;32m      4\u001b[0m                              [\u001b[38;5;241m0.70710678\u001b[39m, \u001b[38;5;241m1.\u001b[39m        ]]))\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert np.allclose(model.get_pairwise_distances(np.array([[0  , 1]  , [1, 1]]), \n",
    "                                                np.array([[0.5, 0.5], [1, 0]])),\n",
    "                   np.array([[0.70710678, 1.41421356],\n",
    "                             [0.70710678, 1.        ]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'method' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [503]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtwo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[0;32m      3\u001b[0m                    np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m0\u001b[39m]))\n",
      "Input \u001b[1;32mIn [500]\u001b[0m, in \u001b[0;36mCustomKNeighborsClassifier.get_class_weights\u001b[1;34m(self, y, weights)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mReturns a vector with sum of weights for each class \u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m        corresponds to the weight of the i-th class.\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# <your code>\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m ùë§ùëñ\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pairwise_distances\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mùëíùëùùë†\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'method' and 'float'"
     ]
    }
   ],
   "source": [
    "model.classes_ = ['one', 'two', 'three']\n",
    "assert np.allclose(model.get_class_weights(np.array(['one', 'one', 'three', 'two']), np.array([1, 1, 0, 4])), \n",
    "                   np.array([2,4,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 21 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "_, axes = plt.subplots(nrows=3, ncols=7, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r if label % 2 else plt.cm.afmhot_r)\n",
    "    ax.set_title(label)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "knn.fit(X_train, list(map(str, y_train)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(model.predict_proba(X_test), knn.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, test_acc = fit_evaluate(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc == 1\n",
    "assert test_acc > 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Take a look at the confusion matrix and tell what numbers the model confuses and why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Try different n_neighbors parameters and compare the output probabilities of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Compare both 'uniform' and 'distance' weights and share your thoughts in what situations which parameter can be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest another distance measurement function that could improve the quality of the classification for this task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Suggest different task and distance function that you think would be suitable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Synthetic Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Read the description here: https://www.kaggle.com/c/tabular-playground-series-apr-2021/data. Download the dataset and place it in the *data/titanic/* folder in your working directory.\n",
    "You will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https://www.kaggle.com/c/tabular-playground-series-apr-2021/overview/evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** Find the percentage of missing values for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?\n",
    "\n",
    "< your thoughts >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model, load the test set and make the predictions. Submit them to kaggle and see the results :)\n",
    "\n",
    "**Note**. X points will depend on your kaggle public leaderboard score.\n",
    "$$ f(score) = 1.0, \\ \\ 0.79 \\leq score < 0.80,$$\n",
    "$$ f(score) = 2.5, \\ \\ 0.80 \\leq score < 0.81,$$ \n",
    "$$ f(score) = 4.0, \\ \\ 0.81 \\leq score $$ \n",
    "Your code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
